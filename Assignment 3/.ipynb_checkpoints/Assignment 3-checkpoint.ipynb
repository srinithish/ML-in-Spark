{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "import numpy as np\n",
    "import random\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark\n",
    "print(pyspark.__version__)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Assign1\").getOrCreate()    \n",
    "spark.conf.set(\"spark.executor.memory\", '30g')\n",
    "spark.conf.set(\"spark.driver.memory\",'30g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AmazonDF = spark.read.csv(\"Amazon.csv\",header=True,sep=\",\",inferSchema=True).limit(100)\n",
    "GoogleDF = spark.read.csv(\"Google.csv\",header=True,sep=\",\",inferSchema=True).limit(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Implement a function that takes a string and returns non-empty tokens by splitting using regular expressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'hello', 'know']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(string,stopWordsList):\n",
    "    \n",
    "    words = re.split('\\W+|\\s|\\.',string)\n",
    "    \n",
    "    words = [word for word in words if word not in stopWordsList and word != '']\n",
    "    \n",
    "    \n",
    "    return words\n",
    "\n",
    "tokenize('he hello know','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsList =  spark.read.csv(\"stopwords.txt\",header=True,sep='\\n',inferSchema=True).collect()\n",
    "stopWordsList = [i['!!'] for i in stopWordsList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|                  id|tokenised_description|\n",
      "+--------------------+---------------------+\n",
      "|http://www.google...| [learning, quickb...|\n",
      "|http://www.google...| [fun, reading, wr...|\n",
      "|http://www.google...| [qb, pos, 6, 0, b...|\n",
      "|http://www.google...| [save, spectacle,...|\n",
      "|http://www.google...| [adobe, cs3, prod...|\n",
      "|http://www.google...| [corel, video, st...|\n",
      "|http://www.google...| [whether, working...|\n",
      "|http://www.google...| [qb, pos, 6, 0, p...|\n",
      "|http://www.google...| [quickbooks, cred...|\n",
      "|http://www.google...| [sony, media, sof...|\n",
      "|http://www.google...| [qb, pos, 6, 0, p...|\n",
      "|http://www.google...| [decide, fate, ga...|\n",
      "|http://www.google...| [based, tween, li...|\n",
      "|http://www.google...| [cisco, systems, ...|\n",
      "|http://www.google...| [wasp, bar, code,...|\n",
      "|http://www.google...| [axis, communicat...|\n",
      "|http://www.google...| [hp, eu063av, aba...|\n",
      "|http://www.google...| [ibm, bb0gyna, us...|\n",
      "|http://www.google...| [equisys, eqzfn07...|\n",
      "|http://www.google...| [wasp, bar, code,...|\n",
      "+--------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GoogleDF = GoogleDF.filter(GoogleDF.description.isNotNull())\n",
    "googleTokens = GoogleDF.select('id','description').rdd.map(lambda x: (x['id'],tokenize(x['description'],stopWordsList)))\n",
    "googleTokensDf = spark.createDataFrame(googleTokens, [\"id\", \"tokenised_description\"])\n",
    "googleTokensDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+\n",
      "|        id|tokenised_description|\n",
      "+----------+---------------------+\n",
      "|b0006zf55o| [oem, arcserve, b...|\n",
      "|b000g80lqo| [peachtree, premi...|\n",
      "|b0006se5bq| [singing, coach, ...|\n",
      "|b000ehpzv8| [emc, retrospect,...|\n",
      "|b00021xhzw| [upgrade, install...|\n",
      "|b000gzwjgc| [marketing, infor...|\n",
      "|b0000dbykm| [mia, s, math, ad...|\n",
      "|b00029bqa2| [disney, s, 1st, ...|\n",
      "|b0007prnjo| [many, times, hea...|\n",
      "|b000aazr5i| [marketing, infor...|\n",
      "|b000bhl1r8| [sql, server, com...|\n",
      "|b00006hmwc| [reference, domin...|\n",
      "|b00006hvvo| [today, enterpris...|\n",
      "|b0000ycfcw| [topics, presents...|\n",
      "|b00002sac9| [now, featuring, ...|\n",
      "|b000bcz8ng| [world, book, enc...|\n",
      "|b000fm18vi| [chord, display, ...|\n",
      "|b00009apna| [complete, easy, ...|\n",
      "|b0009rgzgm| [use, computer, r...|\n",
      "|b000o24l3q| [note, upgrade, v...|\n",
      "+----------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AmazonDF = AmazonDF.filter(AmazonDF.description.isNotNull())\n",
    "amazonTokens = AmazonDF.select('id','description').rdd.map(lambda x: (x['id'],tokenize(x['description'],stopWordsList)))\n",
    "amazonTokensDf = spark.createDataFrame(amazonTokens, [\"id\", \"tokenised_description\"])\n",
    "amazonTokensDf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|               value|\n",
      "+--------------------+--------------------+\n",
      "|http://www.google...|[quickbooks -> 1,...|\n",
      "|http://www.google...|[solving -> 1, re...|\n",
      "|http://www.google...|[retailers -> 1, ...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "def getTermFrequency(inpList):\n",
    "    freqDict = Counter(inpList)\n",
    "    return dict(freqDict)\n",
    "\n",
    "\n",
    "googleTermFreq=googleTokens.map(lambda x:(x[0],getTermFrequency(x[1])))\n",
    "googleTermFreq = spark.createDataFrame(googleTermFreq, [\"id\", \"value\"])\n",
    "googleTermFreq.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|        id|               value|\n",
      "+----------+--------------------+\n",
      "|b0006zf55o|[1 -> 1, arcserve...|\n",
      "|b000g80lqo|[year -> 1, advan...|\n",
      "|b0006se5bq|[singing -> 1, nt...|\n",
      "+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "amazonTermFreq=amazonTokens.map(lambda x:(x[0],getTermFrequency(x[1])))\n",
    "amazonTermFreq = spark.createDataFrame(amazonTermFreq, [\"id\", \"value\"])\n",
    "amazonTermFreq.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using HashingTF and IDF functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"tokenised_description\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(amazonTokensDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|        id|            features|\n",
      "+----------+--------------------+\n",
      "|b0006zf55o|(262144,[39881,55...|\n",
      "|b000g80lqo|(262144,[15,9886,...|\n",
      "|b0006se5bq|(262144,[47491,59...|\n",
      "|b000ehpzv8|(262144,[13087,63...|\n",
      "|b00021xhzw|(262144,[15,353,4...|\n",
      "|b000gzwjgc|(262144,[329,1879...|\n",
      "|b0000dbykm|(262144,[19492,19...|\n",
      "|b00029bqa2|(262144,[20495,21...|\n",
      "|b0007prnjo|(262144,[1998,578...|\n",
      "|b000aazr5i|(262144,[573,2437...|\n",
      "|b000bhl1r8|(262144,[966,1799...|\n",
      "|b00006hmwc|(262144,[15013,17...|\n",
      "|b00006hvvo|(262144,[15,4525,...|\n",
      "|b0000ycfcw|(262144,[30425,34...|\n",
      "|b00002sac9|(262144,[413,5795...|\n",
      "|b000bcz8ng|(262144,[1652,105...|\n",
      "|b000fm18vi|(262144,[39221,80...|\n",
      "|b00009apna|(262144,[15664,17...|\n",
      "|b0009rgzgm|(262144,[15,13828...|\n",
      "|b000o24l3q|(262144,[15,353,2...|\n",
      "+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"id\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4\n",
    "Combine the datasets to create a corpus. Each element of the corpus is a <key, value> pair where key is ID and value is associated tokens from two datasets combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+\n",
      "|                  id|tokenised_description|\n",
      "+--------------------+---------------------+\n",
      "|http://www.google...| [learning, quickb...|\n",
      "|http://www.google...| [fun, reading, wr...|\n",
      "|http://www.google...| [qb, pos, 6, 0, b...|\n",
      "|http://www.google...| [save, spectacle,...|\n",
      "|http://www.google...| [adobe, cs3, prod...|\n",
      "|http://www.google...| [corel, video, st...|\n",
      "|http://www.google...| [whether, working...|\n",
      "|http://www.google...| [qb, pos, 6, 0, p...|\n",
      "|http://www.google...| [quickbooks, cred...|\n",
      "|http://www.google...| [sony, media, sof...|\n",
      "+--------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combinedText=googleTokensDf.union(amazonTokensDf)\n",
    "\n",
    "combinedText.show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "Write an IDF function that return a pair RDD where key is each unique token and value is corresponding IDF value. Plot a histogram of IDF values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIDF()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
